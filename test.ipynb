{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from facenet.models.mtcnn import MTCNN\n",
    "from utils.functions import extract_face\n",
    "\n",
    "image = cv.imread(\"images/cmnd.jpg\")\n",
    "\n",
    "rgb_image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "face, box, _ = extract_face(rgb_image, mtcnn)\n",
    "\n",
    "plt.imshow(face)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread(\"images/cmnd.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "_,thresh = cv2.threshold(gray,128,255,cv2.THRESH_BINARY)\n",
    "plt.imshow(thresh, 'gray')\n",
    "\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "element = cv2.getStructuringElement(shape=cv2.MORPH_RECT, ksize=(7, 7))\n",
    "\n",
    "dilate = cv2.dilate(thresh,element,6)\n",
    "plt.imshow(dilate, 'gray')\n",
    "erode = cv2.erode(dilate,element,6)\n",
    "plt.imshow(erode, 'gray')\n",
    "\n",
    "morph_img = thresh.copy()\n",
    "cv2.morphologyEx(src=erode, op=cv2.MORPH_CLOSE, kernel=element, dst=morph_img)\n",
    "plt.imshow(morph_img, 'gray')\n",
    "contours,_ = cv2.findContours(morph_img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "areas = [cv2.contourArea(c) for c in contours]\n",
    "\n",
    "sorted_areas = np.sort(areas)\n",
    "cnt=contours[areas.index(sorted_areas[-3])] #the third biggest contour is the face\n",
    "r = cv2.boundingRect(cnt)\n",
    "cv2.rectangle(image,(r[0],r[1]),(r[0]+r[2],r[1]+r[3]),(0,0,255),2)\n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_verification import *\n",
    "from verification_models import VGGFace2, VGGFace\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "detector_model = MTCNN(device = device)\n",
    "\n",
    "image = cv.imread(\"images/template.jpg\")\n",
    "\n",
    "rgb_image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "boxes, _, = detector_model.detect(rgb_image)\n",
    "\n",
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded successfully from path: d:\\eKYC\\verification_models\\weights/vggface2_weights.pt\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "from face_verification import *\n",
    "from verification_models import VGGFace2, VGGFace\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "detector_model = MTCNN(device = device)\n",
    "face2 = VGGFace2.load_model(device = device)\n",
    "face1 = VGGFace.load_model(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([580]) tensor([580])\n",
      "tensor([466]) tensor([466])\n",
      "tensor([True])\n",
      "tensor([True])\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"images/trang2.jpg\"\n",
    "filename2 = \"images/trang.jpg\"\n",
    "\n",
    "image1 = get_image(filename1)\n",
    "image2 = get_image(filename2)\n",
    "\n",
    "\n",
    "results = verify(image1, image2, detector_model, face1)\n",
    "results2 = verify(image1, image2, detector_model, face2, model_name = 'VGG-Face2')\n",
    "\n",
    "print(results)\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2414]) tensor([2414])\n",
      "tensor([466]) tensor([466])\n",
      "tensor([True])\n",
      "tensor([True])\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"images/thanh2.png\"\n",
    "filename2 = \"images/thanh4.jpg\"\n",
    "\n",
    "image1 = get_image(filename1)\n",
    "image2 = get_image(filename2)\n",
    "\n",
    "\n",
    "results = verify(image1, image2, detector_model, face1)\n",
    "results2 = verify(image1, image2, detector_model, face2, model_name = 'VGG-Face2')\n",
    "\n",
    "print(results)\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([866]) tensor([866])\n",
      "tensor([466]) tensor([466])\n",
      "tensor([True])\n",
      "tensor([True])\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"images/ngoc.jpg\"\n",
    "filename2 = \"images/ngoc2.jpg\"\n",
    "\n",
    "image1 = get_image(filename1)\n",
    "image2 = get_image(filename2)\n",
    "\n",
    "\n",
    "results = verify(image1, image2, detector_model, face1)\n",
    "results2 = verify(image1, image2, detector_model, face2, model_name = 'VGG-Face2')\n",
    "\n",
    "print(results)\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([571]) tensor([866])\n",
      "tensor([466]) tensor([466])\n",
      "tensor([False])\n",
      "tensor([True])\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"images/thanh.jpg\"\n",
    "filename2 = \"images/ngoc2.jpg\"\n",
    "\n",
    "image1 = get_image(filename1)\n",
    "image2 = get_image(filename2)\n",
    "\n",
    "\n",
    "results = verify(image1, image2, detector_model, face1)\n",
    "results2 = verify(image1, image2, detector_model, face2, model_name = 'VGG-Face2')\n",
    "\n",
    "print(results)\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1, 123'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '123'\n",
    "b = 1\n",
    "f\"{b}, {a}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
